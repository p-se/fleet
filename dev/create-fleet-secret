#!/bin/bash

set -x

# upstream_ctx=$(kubectl config current-context)
# downstream_ctx="$upstream_ctx"

upstream_ctx="k3d-upstream"
downstream_ctx="k3d-downstream"

namespace="fleet-default"
registration_namespace="cluster-$namespace-1a3d67d0a899"
request_name="request-554wl" # cluster registration request name
cluster_name="foo"

# on upstream

kubectl config use-context "$upstream_ctx"

kubectl create ns "$registration_namespace"
kubectl create ns "$namespace"

# create once per installation

cat <<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fleet-bundle-deployment
rules:
- apiGroups:
  - fleet.cattle.io
  resources:
  - bundledeployments
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - fleet.cattle.io
  resources:
  - bundledeployments/status
  verbs:
  - update
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fleet-content
rules:
- apiGroups:
  - fleet.cattle.io
  resources:
  - contents
  verbs:
  - get
EOF

# create cluster

cat <<EOF | kubectl apply -f -
apiVersion: fleet.cattle.io/v1alpha1
kind: Cluster
metadata:
  labels:
    name: $cluster_name
  name: $cluster_name
  namespace: $namespace
spec:
  clientID: j675lg6tzfgt475ndplw45wzmkqvc7sngwg5fmfqcmbgkxfw6d5zpf
EOF

# create per cluster registration namespace
#
# // Add role bindings to manage bundledeployments and contents,
# // the agent could previously only access secrets in
# // 'cattle-fleet-clusters-system' and clusterregistrations in
# // the cluster registration namespace (e.g. 'fleet-default'). See
# // clusterregistrationtoken controller for details.

cat <<EOF | kubectl apply -f -
# TODO isn't the name too specific? Shouldn't this role be used for all cluster registration requests?

apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  annotations:
  labels:
    fleet.cattle.io/managed: "true"
  name: $request_name
  namespace: $namespace
rules:
- apiGroups:
  - fleet.cattle.io
  resourceNames:
  - $cluster_name
  resources:
  - clusters/status
  verbs:
  - patch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    fleet.cattle.io/managed: "true"
  name: $request_name
  namespace: $namespace
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: $request_name
subjects:
- kind: ServiceAccount
  name: $request_name-ea5dd8d8-fe9c-487b-9a25-18653170e960
  namespace: $registration_namespace
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    fleet.cattle.io/managed: "true"
  name: $request_name
  namespace: $registration_namespace
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: fleet-bundle-deployment
subjects:
- kind: ServiceAccount
  name: $request_name-ea5dd8d8-fe9c-487b-9a25-18653170e960
  namespace: $registration_namespace
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    fleet.cattle.io/managed: "true"
  name: $request_name-content
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: fleet-content
subjects:
- kind: ServiceAccount
  name: $request_name-ea5dd8d8-fe9c-487b-9a25-18653170e960
  namespace: $registration_namespace
---
# create request service account
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    fleet.cattle.io/cluster: $cluster_name
    fleet.cattle.io/cluster-registration: $request_name
    fleet.cattle.io/cluster-registration-namespace: $namespace
  labels:
    fleet.cattle.io/managed: "true"
  name: $request_name-ea5dd8d8-fe9c-487b-9a25-18653170e960
  namespace: $registration_namespace
EOF

# kubectl create token $request_name-ea5dd8d8-fe9c-487b-9a25-18653170e960 -n $registration_namespace

cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  annotations:
    kubernetes.io/service-account.name: $request_name-ea5dd8d8-fe9c-487b-9a25-18653170e960
  name: $request_name-ea5dd8d8-fe9c-487b-9a25-18653170e960-token
  namespace: $registration_namespace
type: kubernetes.io/service-account-token
EOF

# wait for token
sleep 1

# fetching from local kubeconfig
host=$(docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' k3d-upstream-server-0)
server="https://$host:6443"
#client_cert=$( kubectl config view --flatten -o jsonpath='{.users[?(@.name == "admin@k3d-upstream")].user.client-certificate-data}' )

# TODO cattle-fleet-clusters-system

kubeconfig_ca=$(kubectl get secret -n "$registration_namespace" $request_name-ea5dd8d8-fe9c-487b-9a25-18653170e960-token -o go-template='{{index .data "ca.crt"}}')
kubeconfig_token=$(kubectl get secret -n "$registration_namespace" $request_name-ea5dd8d8-fe9c-487b-9a25-18653170e960-token -ojson | jq -r '.data.token' | base64 -d)
kubeconfig_namespace=$(kubectl get secret -n "$registration_namespace" $request_name-ea5dd8d8-fe9c-487b-9a25-18653170e960-token -ojson | jq -r '.data.namespace' | base64 -d)

# From there it's for downstream

kubeconfig=$(
  cat <<EOF
apiVersion: v1
kind: Config
current-context: default
clusters:
- cluster:
    certificate-authority-data: $kubeconfig_ca
    server: $server
  name: cluster
contexts:
- context:
    cluster: cluster
    user: user
    namespace: $kubeconfig_namespace
  name: default
preferences: {}
users:
- name: user
  user:
    token: $kubeconfig_token
EOF
)

kubectl config use-context "$downstream_ctx"

kubectl create ns cattle-fleet-system || true
kubectl delete secret -n cattle-fleet-system fleet-agent || true

kubectl create secret generic -n cattle-fleet-system fleet-agent \
  --from-literal=kubeconfig="$kubeconfig" \
  --from-literal=clusterName=$cluster_name \
  --from-literal=clusterNamespace=$namespace \
  --from-literal=deploymentNamespace="$registration_namespace"

helm -n cattle-fleet-system upgrade --install --create-namespace fleet-agent-unmanaged charts/fleet-agent --set-string labels.env=test --set clusterNamespace="$namespace" --set internal.managedReleaseName=fleet-agent-unmanaged --set apiServerURL="$server" --set apiServerCa="$kubeconfig_ca" --set agentmanagement.enabled=false
