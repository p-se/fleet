#!/bin/bash

upstream_ctx=$(kubectl config current-context)
downstream_ctx="$upstream_ctx"

# on upstream

# create once per installation
cat <<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fleet-bundle-deployment
rules:
- apiGroups:
  - fleet.cattle.io
  resources:
  - bundledeployments
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - fleet.cattle.io
  resources:
  - bundledeployments/status
  verbs:
  - update
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fleet-content
rules:
- apiGroups:
  - fleet.cattle.io
  resources:
  - contents
  verbs:
  - get
EOF



# create cluster
#

cat <<EOF | kubectl apply -f -
apiVersion: fleet.cattle.io/v1alpha1
kind: Cluster
metadata:
  labels:
    name: local
  name: local
  namespace: fleet-local
spec:
  clientID: j675lg6tzfgt475ndplw45wzmkqvc7sngwg5fmfqcmbgkxfw6d5zpf
EOF

# create per cluster registration namespace
#
# // Add role bindings to manage bundledeployments and contents,
# // the agent could previously only access secrets in
# // 'cattle-fleet-clusters-system' and clusterregistrations in
# // the cluster registration namespace (e.g. 'fleet-default'). See
# // clusterregistrationtoken controller for details.

cat <<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  annotations:
  labels:
    fleet.cattle.io/managed: "true"
  name: request-554wl
  namespace: fleet-local
rules:
- apiGroups:
  - fleet.cattle.io
  resourceNames:
  - local
  resources:
  - clusters/status
  verbs:
  - patch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    fleet.cattle.io/managed: "true"
  name: request-554wl
  namespace: fleet-local
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: request-554wl
subjects:
- kind: ServiceAccount
  name: request-554wl-ea5dd8d8-fe9c-487b-9a25-18653170e960
  namespace: cluster-fleet-local-local-1a3d67d0a899
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    fleet.cattle.io/managed: "true"
  name: request-554wl
  namespace: cluster-fleet-local-local-1a3d67d0a899
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: fleet-bundle-deployment
subjects:
- kind: ServiceAccount
  name: request-554wl-ea5dd8d8-fe9c-487b-9a25-18653170e960
  namespace: cluster-fleet-local-local-1a3d67d0a899
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    fleet.cattle.io/managed: "true"
  name: request-554wl-content
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: fleet-content
subjects:
- kind: ServiceAccount
  name: request-554wl-ea5dd8d8-fe9c-487b-9a25-18653170e960
  namespace: cluster-fleet-local-local-1a3d67d0a899
---
# create request service account
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    fleet.cattle.io/cluster: local
    fleet.cattle.io/cluster-registration: request-554wl
    fleet.cattle.io/cluster-registration-namespace: fleet-local
  labels:
    fleet.cattle.io/managed: "true"
  name: request-554wl-ea5dd8d8-fe9c-487b-9a25-18653170e960
  namespace: cluster-fleet-local-local-1a3d67d0a899
EOF

# kubectl create token request-554wl-ea5dd8d8-fe9c-487b-9a25-18653170e960 -n cluster-fleet-local-local-1a3d67d0a899

cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  annotations:
    kubernetes.io/service-account.name: request-554wl-ea5dd8d8-fe9c-487b-9a25-18653170e960
  name: request-554wl-ea5dd8d8-fe9c-487b-9a25-18653170e960-token
  namespace: cluster-fleet-local-local-1a3d67d0a899
type: kubernetes.io/service-account-token
EOF

# wait for token
sleep 1



# fetching from local kubeconfig
host=$( docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' k3d-upstream-server-0 )
server="https://$host:6443"
#client_cert=$( kubectl config view --flatten -o jsonpath='{.users[?(@.name == "admin@k3d-upstream")].user.client-certificate-data}' )

# TODO cattle-fleet-clusters-system
ca=$(kubectl get secret -n cluster-fleet-local-local-1a3d67d0a899 request-554wl-ea5dd8d8-fe9c-487b-9a25-18653170e960-token -o go-template='{{index .data "ca.crt"}}')
token=$(kubectl get secret -n cluster-fleet-local-local-1a3d67d0a899 request-554wl-ea5dd8d8-fe9c-487b-9a25-18653170e960-token -ojson | jq -r '.data.token')

# ab hier downstream
kubeconfig=$(cat <<EOF
apiVersion: v1
kind: Config
current-context: default
clusters:
- cluster:
    certificate-authority-data: $ca
    server: $server
  name: cluster
contexts:
- context:
    cluster: cluster
    user: user
  name: default
preferences: {}
users:
- name: user
  user:
    client-key-data: $token
EOF
)

# clusterName, clusterNamespace, deploymentNamespace
kubectl delete secret -n cattle-fleet-system fleet-agent || true
kubectl create secret generic -n cattle-fleet-system fleet-agent --from-literal=kubeconfig="$kubeconfig"

# helm -n cattle-fleet-system upgrade --install --create-namespace fleet-agent-local charts/fleet-agent --set-string labels.env=test --set clusterNamespace="fleet-local" --set internal.managedReleaseName=fleet-agent-local
